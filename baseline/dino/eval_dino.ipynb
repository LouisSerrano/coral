{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pickletools import OpcodeInfo\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from coral.utils.data.dynamics_dataset import (KEY_TO_INDEX, TemporalDatasetWithCode)\n",
    "from coral.utils.models.load_inr import create_inr_instance, load_inr_model\n",
    "from coral.utils.data.load_data import get_dynamics_data, set_seed\n",
    "from utils import scheduling\n",
    "from ode_model import Decoder, Derivative\n",
    "from torchdiffeq import odeint\n",
    "from eval_dino import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = DictConfig(yaml.safe_load(open(\"config.yaml\")))\n",
    "dataset_name = cfg.data.dataset_name\n",
    "dataset_name = 'navier-stokes-dino'\n",
    "run_name = cfg.inr.run_name\n",
    "\n",
    "root_dir = Path(os.getenv(\"WANDB_DIR\")) / dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dyn_model \n",
    "\n",
    "tmp = torch.load(root_dir / \"dino\" / \"model\" / f\"{run_name}.pt\")\n",
    "#cfg = tmp['cfg']\n",
    "dec_state = tmp['dec_state_dict']\n",
    "dyn_state = tmp['dyn_state_dict']\n",
    "\n",
    "data_dir = cfg.data.dir\n",
    "ntrain = cfg.data.ntrain\n",
    "ntest = cfg.data.ntest\n",
    "sub_from = cfg.data.sub_from\n",
    "sub_tr = cfg.data.sub_tr\n",
    "sub_te = cfg.data.sub_te\n",
    "seed = cfg.data.seed\n",
    "same_grid = cfg.data.same_grid\n",
    "seq_inter_len = cfg.data.seq_inter_len\n",
    "seq_extra_len = cfg.data.seq_extra_len\n",
    "\n",
    "# optim\n",
    "batch_size = cfg.optim.minibatch_size\n",
    "lr = cfg.optim.lr\n",
    "\n",
    "# inr\n",
    "state_dim = cfg.inr.state_dim\n",
    "code_dim = cfg.inr.code_dim\n",
    "hidden_c_enc = cfg.inr.hidden_c_enc\n",
    "n_layers = cfg.inr.n_layers\n",
    "coord_dim = cfg.inr.coord_dim\n",
    "\n",
    "# forecaster\n",
    "hidden_c = cfg.forecaster.hidden_c\n",
    "\n",
    "# Decoder\n",
    "net_dec_params = {\n",
    "    \"state_c\": state_dim,\n",
    "    \"code_c\": code_dim,\n",
    "    \"hidden_c\": hidden_c_enc,\n",
    "    \"n_layers\": n_layers,\n",
    "    \"coord_dim\": coord_dim,\n",
    "}\n",
    "# Forecaster\n",
    "net_dyn_params = {\n",
    "    \"state_c\": state_dim,\n",
    "    \"hidden_c\": hidden_c,\n",
    "    \"code_c\": code_dim,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_tr, sub_from, sub_te :  0.2 2 0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"sub_tr, sub_from, sub_te : \", sub_tr, sub_from, sub_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['net.bilinear.0.A', 'net.bilinear.0.B', 'net.bilinear.0.bias', 'net.bilinear.1.A', 'net.bilinear.1.B', 'net.bilinear.1.bias', 'net.bilinear.2.A', 'net.bilinear.2.B', 'net.bilinear.2.bias', 'net.bilinear.3.A', 'net.bilinear.3.B', 'net.bilinear.3.bias', 'net.output_bilinear.weight', 'net.output_bilinear.bias', 'net.filters.0.weight', 'net.filters.1.weight', 'net.filters.2.weight', 'net.filters.3.weight'])\n",
      "dict_keys(['net.net.0.weight', 'net.net.0.bias', 'net.net.1.beta', 'net.net.2.weight', 'net.net.2.bias', 'net.net.3.beta', 'net.net.4.weight', 'net.net.4.bias', 'net.net.5.beta', 'net.net.6.weight', 'net.net.6.bias'])\n",
      "data: navier-stokes-dino, u_train: torch.Size([256, 20, 13107, 1]), u_train_eval: torch.Size([256, 40, 13107, 1]), u_test: torch.Size([16, 40, 13107, 1])\n",
      "grid: grid_tr: torch.Size([256, 20, 13107, 2]), grid_tr_extra: torch.Size([256, 40, 13107, 2]), grid_te: torch.Size([16, 40, 13107, 2])\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "if dataset_name == 'shallow-water-dino':\n",
    "    multichannel = True\n",
    "else:\n",
    "    multichannel = False\n",
    "\n",
    "(u_train, u_eval_extrapolation, u_test, grid_tr, grid_tr_extra, grid_te) = get_dynamics_data(\n",
    "    data_dir,\n",
    "    dataset_name,\n",
    "    ntrain,\n",
    "    ntest,\n",
    "    seq_inter_len=seq_inter_len,\n",
    "    seq_extra_len=seq_extra_len,\n",
    "    sub_tr=sub_tr,\n",
    "    sub_te=sub_te,\n",
    "    same_grid=same_grid,\n",
    ")\n",
    "\n",
    "u_train = einops.rearrange(u_train, 'N ... T -> N T ...')\n",
    "u_eval_extrapolation = einops.rearrange(u_eval_extrapolation, 'N ... T -> N T ...')\n",
    "u_test = einops.rearrange(u_test, 'N ... T -> N T ...')\n",
    "grid_tr = einops.rearrange(grid_tr, 'N ... T -> N T ...')\n",
    "grid_tr_extra = einops.rearrange(grid_tr_extra, 'N ... T -> N T ...')\n",
    "grid_te = einops.rearrange(grid_te, 'N ... T -> N T ...')\n",
    "\n",
    "trainset = TemporalDatasetWithCode(\n",
    "    u_train, grid_tr, code_dim, dataset_name, None\n",
    ")\n",
    "\n",
    "trainset_extra = TemporalDatasetWithCode(\n",
    "    u_eval_extrapolation, grid_tr_extra, code_dim, dataset_name, None\n",
    ")\n",
    "testset = TemporalDatasetWithCode(\n",
    "    u_test, grid_te, code_dim, dataset_name, None\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "train_extra_loader = torch.utils.data.DataLoader(\n",
    "    trainset_extra,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "n_seq_train = u_train.shape[0]\n",
    "n_seq_test = u_test.shape[0]\n",
    "T_train = u_train.shape[1]\n",
    "T_test = u_test.shape[1]\n",
    "dt = 1\n",
    "\n",
    "timestamps_train = torch.arange(0, T_train, dt).float().cuda()\n",
    "timestamps_test = torch.arange(0, T_test, dt).float().cuda()\n",
    "\n",
    "method = \"rk4\"\n",
    "\n",
    "if dataset_name == \"shallow-water-dino\":\n",
    "    n_steps = 500\n",
    "else:\n",
    "    n_steps = 300\n",
    "\n",
    "net_dec = Decoder(**net_dec_params)\n",
    "net_dec_dict = net_dec.state_dict()\n",
    "pretrained_dict = {\n",
    "    k: v for k, v in dec_state.items() if k in net_dec_dict\n",
    "}\n",
    "net_dec_dict.update(pretrained_dict)\n",
    "net_dec.load_state_dict(pretrained_dict)\n",
    "print(dict(net_dec.named_parameters()).keys())\n",
    "\n",
    "net_dyn = Derivative(**net_dyn_params)\n",
    "net_dyn_dict = net_dyn.state_dict()\n",
    "pretrained_dict = {\n",
    "    k: v for k, v in dyn_state.items() if k in net_dyn_dict\n",
    "}\n",
    "net_dyn_dict.update(pretrained_dict)\n",
    "net_dyn.load_state_dict(net_dyn_dict)\n",
    "print(dict(net_dyn.named_parameters()).keys())\n",
    "\n",
    "states_params = tmp[\"states_params\"]\n",
    "net_dec = net_dec.to('cuda')\n",
    "net_dyn = net_dyn.to('cuda')\n",
    "\n",
    "print(f\"data: {dataset_name}, u_train: {u_train.shape}, u_train_eval: {u_eval_extrapolation.shape}, u_test: {u_test.shape}\")\n",
    "print(f\"grid: grid_tr: {grid_tr.shape}, grid_tr_extra: {grid_tr_extra.shape}, grid_te: {grid_te.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetailedMSE():\n",
    "    def __init__(self, keys, dataset_name=\"shallow-water-dino\", mode=\"train\", n_trajectories=256):\n",
    "        self.keys = keys\n",
    "        self.mode = mode\n",
    "        self.dataset_name = dataset_name\n",
    "        self.n_trajectories = n_trajectories\n",
    "        self.reset_dic()\n",
    "\n",
    "    def reset_dic(self):\n",
    "        dic = {}\n",
    "        for key in self.keys:\n",
    "            dic[f\"{key}_{self.mode}_mse\"] = 0\n",
    "        self.dic = dic\n",
    "\n",
    "    def aggregate(self, u_pred, u_true):\n",
    "        n_samples = u_pred.shape[0]\n",
    "        for key in self.keys:\n",
    "            idx = KEY_TO_INDEX[self.dataset_name][key]\n",
    "            self.dic[f\"{key}_{self.mode}_mse\"] += (\n",
    "                (u_pred[..., idx, :] - u_true[..., idx, :])**2).mean()*n_samples\n",
    "\n",
    "    def get_dic(self):\n",
    "        dic = self.dic\n",
    "        for key in self.keys:\n",
    "            dic[f\"{key}_{self.mode}_mse\"] /= self.n_trajectories\n",
    "        return self.dic \n",
    "    \n",
    "if multichannel:\n",
    "    detailed_train_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                        dataset_name,\n",
    "                                        mode=\"train\",\n",
    "                                        n_trajectories=ntrain)\n",
    "    detailed_train_eval_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                        dataset_name,\n",
    "                                        mode=\"train_extra\",\n",
    "                                        n_trajectories=ntrain)\n",
    "    detailed_test_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                    dataset_name,\n",
    "                                    mode=\"test\",\n",
    "                                    n_trajectories=ntest)\n",
    "else:\n",
    "    detailed_test_mse = None\n",
    "    detailed_train_eval_mse = None\n",
    "    detailed_train_mse = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating train...\n",
      "Evaluating test...\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"Evaluating train...\")\n",
    "pred_train_mse, pred_train_inter_mse, pred_train_extra_mse, detailed_train_eval_mse = eval_dino(\n",
    "    train_extra_loader, net_dyn, net_dec, 'cuda', method, criterion, state_dim, code_dim, coord_dim, \n",
    "    detailed_train_eval_mse, timestamps_test, n_seq_train, seq_inter_len, seq_extra_len, states_params, \n",
    "    multichannel=multichannel, n_steps=n_steps,\n",
    ")\n",
    "\n",
    "# Out-of-domain evaluation\n",
    "print(\"Evaluating test...\")\n",
    "pred_test_mse, pred_test_inter_mse, pred_test_extra_mse, detailed_test_mse = eval_dino(\n",
    "    test_loader, net_dyn, net_dec, 'cuda', method, criterion, state_dim, code_dim, coord_dim, \n",
    "    detailed_test_mse, timestamps_test, n_seq_test, seq_inter_len, seq_extra_len,\n",
    "    states_params, lr, multichannel=multichannel, n_steps=n_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_train_inter_mse :  0.010746166815806646\n",
      "pred_train_extra_mse : 0.0488120950612938\n"
     ]
    }
   ],
   "source": [
    "print(\"pred_train_inter_mse : \", pred_train_inter_mse)\n",
    "print('pred_train_extra_mse :' , pred_train_extra_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_test_inter_mse :  0.015077762713190168\n",
      "pred_test_extra_mse : 0.0685730007244274\n"
     ]
    }
   ],
   "source": [
    "print(\"pred_test_inter_mse : \", pred_test_inter_mse)\n",
    "print('pred_test_extra_mse :' , pred_test_extra_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
