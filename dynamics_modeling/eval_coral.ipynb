{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pickletools import OpcodeInfo\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from coral.utils.data.dynamics_dataset import (KEY_TO_INDEX, TemporalDatasetWithCode)\n",
    "from coral.utils.models.load_inr import create_inr_instance, load_inr_model\n",
    "from coral.utils.data.load_data import get_dynamics_data, set_seed\n",
    "from coral.utils.data.load_modulations import load_dynamics_modulations\n",
    "from coral.utils.models.get_inr_reconstructions import get_reconstructions\n",
    "from coral.utils.models.scheduling import ode_scheduling\n",
    "from torchdiffeq import odeint\n",
    "from dynamics_modeling.eval import batch_eval_loop\n",
    "from coral.mlp import MLP, Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import interp2d\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fragrant-bee-4658 # 0.0125\n",
    "iconic-firefly-4657 # 5%\n",
    "atomic-surf-4656 # 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kassai/wandb_logs/navier-stokes-dino\n"
     ]
    }
   ],
   "source": [
    "cfg = DictConfig(yaml.safe_load(open(\"config/ode.yaml\")))\n",
    "dataset_name = cfg.data.dataset_name\n",
    "dataset_name = 'navier-stokes-dino'\n",
    "# dyn\n",
    "load_dyn_run = cfg.dynamics.run_name\n",
    "root_dir = Path(os.getenv(\"WANDB_DIR\")) / dataset_name\n",
    "print(root_dir)\n",
    "load_dyn_run = 'smooth-firebrand-5016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dyn_model \n",
    "\n",
    "tmp_dyn = torch.load(root_dir / \"model\" / f\"{load_dyn_run}.pt\")\n",
    "cfg = tmp_dyn['cfg']\n",
    "model_state = tmp_dyn['model']\n",
    "\n",
    "data_dir = cfg.data.dir\n",
    "ntrain = cfg.data.ntrain\n",
    "ntest = cfg.data.ntest\n",
    "data_to_encode = cfg.data.data_to_encode\n",
    "sub_tr = cfg.data.sub_tr\n",
    "sub_from = cfg.data.sub_from if cfg.data.sub_from is not None else 1\n",
    "sub_te = cfg.data.sub_te\n",
    "seed = cfg.data.seed\n",
    "same_grid = cfg.data.same_grid\n",
    "seq_inter_len = 20\n",
    "seq_extra_len = 20\n",
    "\n",
    "# optim\n",
    "batch_size = cfg.optim.batch_size\n",
    "batch_size_val = (\n",
    "    batch_size if cfg.optim.batch_size_val == None else cfg.optim.batch_size_val\n",
    ")\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_tr, sub_te :  0.2 0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"sub_tr, sub_te : \", sub_tr, sub_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inr\n",
    "load_run_name = cfg.inr.run_name\n",
    "inner_steps = cfg.inr.inner_steps\n",
    "\n",
    "try:\n",
    "    load_run_dict = dict(cfg.inr.run_dict)\n",
    "except TypeError:\n",
    "    load_run_dict = cfg.inr.run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "\n",
    "if data_to_encode is not None:\n",
    "    inr_dir = Path(os.getenv(\"WANDB_DIR\")) / \\\n",
    "        dataset_name / data_to_encode / \"inr\"\n",
    "    modulations_dir = (\n",
    "        Path(os.getenv(\"WANDB_DIR\")) / dataset_name /\n",
    "        data_to_encode / \"modulations\"\n",
    "    )\n",
    "    model_dir = (\n",
    "        Path(os.getenv(\"WANDB_DIR\")) /\n",
    "        dataset_name / data_to_encode / \"model\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    inr_dir = Path(os.getenv(\"WANDB_DIR\")) / dataset_name / \"inr\"\n",
    "    modulations_dir = Path(os.getenv(\"WANDB_DIR\")) / \\\n",
    "        dataset_name / \"modulations\"\n",
    "    model_dir = Path(os.getenv(\"WANDB_DIR\")) / dataset_name / \"model\"\n",
    "\n",
    "# we need the latent dim and the sub_tr used for training\n",
    "if load_run_name is not None:\n",
    "    multichannel = False\n",
    "    tmp = torch.load(root_dir / \"inr\" / f\"{load_run_name}.pt\")\n",
    "    latent_dim = tmp[\"cfg\"].inr.latent_dim\n",
    "\n",
    "elif load_run_dict is not None:\n",
    "    multichannel = True\n",
    "    tmp_data_to_encode = list(load_run_dict.keys())[0]\n",
    "    tmp_run_name = list(load_run_dict.values())[0]\n",
    "    tmp = torch.load(root_dir / tmp_data_to_encode /\n",
    "                        \"inr\" / f\"{tmp_run_name}.pt\")\n",
    "    latent_dim = tmp[\"cfg\"].inr.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: navier-stokes-dino, u_train: torch.Size([256, 3276, 1, 20]), u_train_eval: torch.Size([256, 3276, 1, 40]), u_test: torch.Size([16, 3276, 1, 40])\n",
      "grid: grid_tr: torch.Size([256, 3276, 2, 20]), grid_tr_extra: torch.Size([256, 3276, 2, 40]), grid_te: torch.Size([16, 3276, 2, 40])\n",
      "Train, average loss: 0.000693938372478442\n",
      "Train extra, average loss: 0.00174077078463597\n",
      "Test, average loss: 0.0018292279710294679\n",
      "ztrain_extra torch.Size([256, 128, 40]) tensor(0.0050) tensor(1.0676)\n",
      "ztest torch.Size([16, 128, 40]) tensor(0.0128) tensor(1.0706)\n"
     ]
    }
   ],
   "source": [
    "random =  2 #np.random.randint(1, 8)\n",
    "preds = []\n",
    "truths = []\n",
    "#sub_tes = [0.05, 4, 2, 1]\n",
    "sub_tes = [sub_te]\n",
    "set_seed(seed)\n",
    "for i, sub_te in enumerate(sub_tes):\n",
    "    (u_train, u_train_eval, u_test, grid_tr, grid_tr_extra, grid_te) = get_dynamics_data(\n",
    "        data_dir,\n",
    "        dataset_name,\n",
    "        ntrain,\n",
    "        ntest,\n",
    "        seq_inter_len=seq_inter_len,\n",
    "        seq_extra_len=seq_extra_len,\n",
    "        sub_from = sub_from,\n",
    "        sub_tr=sub_tr,\n",
    "        sub_te=sub_te,\n",
    "        same_grid=same_grid,\n",
    "    )\n",
    "    print(\n",
    "        f\"data: {dataset_name}, u_train: {u_train.shape}, u_train_eval: {u_train_eval.shape}, u_test: {u_test.shape}\")\n",
    "    print(f\"grid: grid_tr: {grid_tr.shape}, grid_tr_extra: {grid_tr_extra.shape}, grid_te: {grid_te.shape}\")\n",
    "\n",
    "    trainset = TemporalDatasetWithCode(\n",
    "        u_train, grid_tr, latent_dim, dataset_name, data_to_encode\n",
    "    )\n",
    "    trainset_extra = TemporalDatasetWithCode(\n",
    "        u_train_eval, grid_tr_extra, latent_dim, dataset_name, data_to_encode\n",
    "    )\n",
    "    testset = TemporalDatasetWithCode(\n",
    "        u_test, grid_te, latent_dim, dataset_name, data_to_encode\n",
    "    )\n",
    "\n",
    "    #total frames trainset\n",
    "    ntrain = trainset.z.shape[0]\n",
    "\n",
    "    #total frames testset\n",
    "    ntest = testset.z.shape[0]\n",
    "\n",
    "    # sequence length \n",
    "    T_train = u_train.shape[-1]\n",
    "    T_test = u_test.shape[-1]\n",
    "\n",
    "    dt = 1\n",
    "    timestamps_train = torch.arange(0, T_train, dt).float().cuda()\n",
    "    timestamps_test = torch.arange(0, T_test, dt).float().cuda()\n",
    "\n",
    "    # trainset coords of shape (N, Dx, Dy, input_dim, T)\n",
    "    input_dim = grid_tr.shape[-2]\n",
    "    # trainset images of shape (N, Dx, Dy, output_dim, T)\n",
    "    output_dim = u_train.shape[-2]\n",
    "\n",
    "    if load_run_name is not None:\n",
    "        inr, alpha = load_inr_model(\n",
    "            root_dir / \"inr\",\n",
    "            load_run_name,\n",
    "            data_to_encode,\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "        )\n",
    "        c = 1\n",
    "        modulations = load_dynamics_modulations(\n",
    "            trainset,\n",
    "            trainset_extra,\n",
    "            testset,\n",
    "            inr,\n",
    "            root_dir / \"modulations\",\n",
    "            load_run_name,\n",
    "            inner_steps=inner_steps,\n",
    "            alpha=alpha,\n",
    "            batch_size=2,\n",
    "            data_to_encode=None,\n",
    "            try_reload=False,\n",
    "        )\n",
    "        z_train = modulations[\"z_train\"]\n",
    "        z_train_extra = modulations[\"z_train_extra\"]\n",
    "        z_test = modulations[\"z_test\"]\n",
    "        z_mean = einops.rearrange(z_train, \"b l t -> (b t) l\").mean(0).reshape(1, latent_dim, 1)#\n",
    "        z_std = einops.rearrange(z_train, \"b l t -> (b t) l\").std(0).reshape(1, latent_dim, 1)\n",
    "        z_train = (z_train - z_mean) / z_std\n",
    "        z_train_extra = (z_train_extra - z_mean) / z_std\n",
    "        z_test = (z_test - z_mean) / z_std\n",
    "\n",
    "    elif load_run_dict is not None:\n",
    "        inr_dict = {}\n",
    "        z_mean = {}\n",
    "        z_std = {}\n",
    "        c = len(list(load_run_dict.keys()))\n",
    "        z_train = torch.zeros(ntrain, latent_dim, c, T_train)\n",
    "        z_train_extra = torch.zeros(ntrain, latent_dim, c, T_test)\n",
    "        z_test = torch.zeros(ntest, latent_dim, c, T_test)\n",
    "\n",
    "        for to_encode in list(load_run_dict.keys()):\n",
    "            tmp_name = load_run_dict[to_encode]\n",
    "            output_dim = 1\n",
    "            inr, alpha = load_inr_model(\n",
    "                root_dir / to_encode / \"inr\",\n",
    "                tmp_name,\n",
    "                to_encode,\n",
    "                input_dim=input_dim,\n",
    "                output_dim=output_dim,\n",
    "            )\n",
    "\n",
    "            trainset.set_data_to_encode(to_encode)\n",
    "            trainset_extra.set_data_to_encode(to_encode)\n",
    "            testset.set_data_to_encode(to_encode)\n",
    "\n",
    "            modulations = load_dynamics_modulations(\n",
    "                trainset,\n",
    "                trainset_extra,\n",
    "                testset,\n",
    "                inr,\n",
    "                root_dir / to_encode / \"modulations\",\n",
    "                tmp_name,\n",
    "                inner_steps=inner_steps,\n",
    "                alpha=alpha,\n",
    "                batch_size=1,\n",
    "                data_to_encode=to_encode,\n",
    "                try_reload=False,\n",
    "            )\n",
    "            inr_dict[to_encode] = inr\n",
    "            z_tr = modulations[\"z_train\"]\n",
    "            z_tr_extra = modulations[\"z_train_extra\"]\n",
    "            z_te = modulations[\"z_test\"]\n",
    "            z_m = einops.rearrange(z_tr, \"b l t -> (b t) l\").mean(0).reshape(1, latent_dim, 1)\n",
    "            z_s = einops.rearrange(z_tr, \"b l t -> (b t) l\").std(0).reshape(1, latent_dim, 1)\n",
    "            z_mean[to_encode] = z_m\n",
    "            z_std[to_encode] = z_s\n",
    "            z_train_extra[..., KEY_TO_INDEX[dataset_name]\n",
    "                    [to_encode], :] = (z_tr_extra - z_m) / z_s\n",
    "            z_test[..., KEY_TO_INDEX[dataset_name]\n",
    "                    [to_encode], :] = (z_te - z_m) / z_s\n",
    "\n",
    "        # concat the code\n",
    "        trainset_extra.set_data_to_encode(None)\n",
    "        testset.set_data_to_encode(None)\n",
    "        # rename inr_dict <- inr\n",
    "        inr = inr_dict\n",
    "\n",
    "    trainset_extra.z = z_train_extra\n",
    "    testset.z = z_test\n",
    "\n",
    "    print('ztrain_extra', z_train_extra.shape, z_train_extra.mean(), z_train_extra.std())\n",
    "    print('ztest', z_test.shape, z_test.mean(), z_test.std())\n",
    "\n",
    "    train_extra_loader = torch.utils.data.DataLoader(\n",
    "        trainset_extra,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    # Load model\n",
    "    hidden = cfg.dynamics.width\n",
    "    depth = cfg.dynamics.depth\n",
    "\n",
    "    model = Derivative(c, z_train.shape[1], hidden, depth).cuda()\n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    model.eval()\n",
    "    ground_truth, modulations, coords = test_loader.dataset[random - 1: random][0], test_loader.dataset[random - 1: random][1], test_loader.dataset[random - 1: random][2]\n",
    "\n",
    "    ground_truth = ground_truth.cuda()\n",
    "    modulations = modulations.cuda()\n",
    "    coords = coords.cuda()\n",
    "\n",
    "    if multichannel:\n",
    "\n",
    "        modulations = einops.rearrange(modulations, \"b l c t -> b (l c) t\")\n",
    "        \n",
    "    z_pred = ode_scheduling(odeint, model, modulations, timestamps_test, 0)\n",
    "    pred = get_reconstructions(\n",
    "        inr, coords, z_pred, z_mean, z_std, dataset_name\n",
    "    )\n",
    "    pred = pred.cpu()\n",
    "    ground_truth = ground_truth.cpu()\n",
    "    preds.append(pred)\n",
    "    truths.append(ground_truth)\n",
    "\n",
    "    if i == 0:\n",
    "        coords_initial = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_baselines(plot_dir, title, preds, truths, channel, view=(100., 0.)):\n",
    "    \n",
    "    T = preds[0].shape[-1]\n",
    "    ims = []\n",
    "    proj = ccrs.Orthographic(*view)\n",
    "\n",
    "    # add subfigure per subplot\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "\n",
    "    # clear subplots\n",
    "\n",
    "    latitude1 = torch.linspace(90.0, -90.0, truths[0].shape[1])\n",
    "    longitude1 = torch.linspace(0.0, 360.0 - (360.0 / truths[0].shape[2]), truths[0].shape[2])\n",
    "    longitude_grid1, latitude_grid1 = torch.meshgrid(longitude1, latitude1, indexing=\"xy\")\n",
    "\n",
    "    latitude2 = torch.linspace(90.0, -90.0, truths[1].shape[1])\n",
    "    longitude2 = torch.linspace(0.0, 360.0 - (360.0 / truths[1].shape[2]), truths[1].shape[2])\n",
    "    longitude_grid2, latitude_grid2 = torch.meshgrid(longitude2, latitude2, indexing=\"xy\")\n",
    "\n",
    "    latitude3 = torch.linspace(90.0, -90.0, truths[2].shape[1])\n",
    "    longitude3 = torch.linspace(0.0, 360.0 - (360.0 / truths[2].shape[2]), truths[2].shape[2])\n",
    "    longitude_grid3, latitude_grid3 = torch.meshgrid(longitude3, latitude3, indexing=\"xy\")\n",
    "    \n",
    "    axes = subfigs[0].subplots(1, 2, subplot_kw={'projection': proj})\n",
    "    subfigs[1].suptitle('Sub_te = 4')\n",
    "    axs = subfigs[1].subplots(1, 2, subplot_kw={'projection': proj})\n",
    "    subfigs[1].suptitle('Sub_te = 2')\n",
    "    ax = subfigs[2].subplots(1, 2, subplot_kw={'projection': proj})\n",
    "    subfigs[2].suptitle('Sub_te = 1')\n",
    "\n",
    "    for i in range(T):\n",
    "        if i < 20:\n",
    "            time = 'In-t'\n",
    "            im0 = axes[0].pcolormesh(longitude_grid1, latitude_grid1, truths[0][0, ..., channel, i],\n",
    "                                transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            axes[0].set_title('Ground truth')\n",
    "            axes[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im1 = axes[1].pcolormesh(longitude_grid1, latitude_grid1, preds[0][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            axes[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            axes[1].set_title('Reconstruction')\n",
    "\n",
    "            im2 = axs[0].pcolormesh(longitude_grid2, latitude_grid2, truths[1][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            axs[0].set_title('Ground truth')\n",
    "            axs[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im3 = axs[1].pcolormesh(longitude_grid2, latitude_grid2, preds[1][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            axs[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            axs[1].set_title('Reconstruction')\n",
    "\n",
    "            im4 = ax[0].pcolormesh(longitude_grid3, latitude_grid3, truths[2][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            ax[0].set_title('Ground truth, {}'.format(time))\n",
    "            ax[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im5 = ax[1].pcolormesh(longitude_grid3, latitude_grid3, preds[2][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='viridis', shading = 'auto')\n",
    "            ax[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            ax[1].set_title('Reconstruction')\n",
    "            ims.append([im0, im1, im2, im3, im4, im5])\n",
    "        elif i >= 20:\n",
    "            time = 'Out-t'\n",
    "\n",
    "            im0 = axes[0].pcolormesh(longitude_grid1, latitude_grid1, truths[0][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            axes[0].set_title('Ground truth')\n",
    "            axes[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im1 = axes[1].pcolormesh(longitude_grid1, latitude_grid1, preds[0][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            axes[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            axes[1].set_title('Reconstruction')\n",
    "\n",
    "            im2 = axs[0].pcolormesh(longitude_grid2, latitude_grid2, truths[1][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            axs[0].set_title('Ground truth')\n",
    "            axs[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im3 = axs[1].pcolormesh(longitude_grid2, latitude_grid2, preds[1][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            axs[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            axs[1].set_title('Reconstruction')\n",
    "\n",
    "            im4 = ax[0].pcolormesh(longitude_grid3, latitude_grid3, truths[2][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            ax[0].set_title('Ground truth')\n",
    "            ax[0].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "\n",
    "            im5 = ax[1].pcolormesh(longitude_grid3, latitude_grid3, preds[2][0, ..., channel, i],\n",
    "                                        transform=ccrs.PlateCarree(), cmap='plasma', shading = 'auto')\n",
    "            ax[1].gridlines(linewidth=1, color='black', alpha=0.05)\n",
    "            ax[1].set_title('Reconstruction')\n",
    "            ims.append([im0, im1, im2, im3, im4, im5])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=150, blit=True,\n",
    "                                    repeat_delay=1000)\n",
    "\n",
    "    ani.save(os.path.join(plot_dir, title),\n",
    "            dpi=300)\n",
    "    \n",
    "def get_grid(mask_prob, title):\n",
    "\n",
    "    num_points = 128*256\n",
    "    coords = grid_te[0, ..., 0, 0].numpy()\n",
    "    perm = torch.randperm(num_points)\n",
    "    perm = perm[: int(mask_prob * len(perm))].clone().sort()[0]\n",
    "    coords = coords.flatten()\n",
    "    coords[perm] = 1\n",
    "    coords = coords == 1\n",
    "    coords = coords.reshape(128, 256)\n",
    "    print(np.unique(coords, return_counts = True))\n",
    "    \n",
    "    proj = ccrs.Orthographic(*(-10, 30))\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (15, 8), subplot_kw={'projection': proj})\n",
    "    latitude = torch.linspace(90.0, -90.0, 128)\n",
    "    longitude = torch.linspace(0.0, 360.0 - (360.0 / 256), 256)\n",
    "    longitude_grid, latitude_grid = torch.meshgrid(longitude, latitude, indexing=\"xy\")\n",
    "\n",
    "    img = ax.pcolormesh(longitude_grid, latitude_grid, coords,\n",
    "                        transform=ccrs.PlateCarree(), shading = 'auto')\n",
    "    ax.gridlines(linewidth=1, color='black', alpha=0.1)\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join('/home/kassai/code/coral/visualizations/table/', title), format='png')\n",
    "\n",
    "def plot_globe(truth,  timestep, title, channel = 1):\n",
    "    proj = ccrs.Orthographic(*(-10, 30))\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (15, 8), subplot_kw={'projection': proj})\n",
    "    latitude = torch.linspace(90.0, -90.0, 128)\n",
    "    longitude = torch.linspace(0.0, 360.0 - (360.0 / 256), 256)\n",
    "    longitude_grid, latitude_grid = torch.meshgrid(longitude, latitude, indexing=\"xy\")\n",
    "\n",
    "    img = ax.pcolormesh(longitude_grid, latitude_grid, truth[0, ..., channel, timestep],\n",
    "                        transform=ccrs.PlateCarree(), cmap='twilight', shading = 'auto')\n",
    "    ax.gridlines(linewidth=1, color='black', alpha=0.1)\n",
    "\n",
    "    plt.show()\n",
    "    #fig.savefig(os.path.join('/home/kassai/code/coral/visualizations/table/5%/', title), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_globe(preds[0], 39, 'timestep_39.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gif_baselines('/home/kassai/code/coral/visualizations/', 'predictions_coral_5%.gif', preds[1:], truths[1:], channel = 1, view = (-10, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetailedMSE():\n",
    "    def __init__(self, keys, dataset_name=\"shallow-water-dino\", mode=\"train\", n_trajectories=256):\n",
    "        self.keys = keys\n",
    "        self.mode = mode\n",
    "        self.dataset_name = dataset_name\n",
    "        self.n_trajectories = n_trajectories\n",
    "        self.reset_dic()\n",
    "\n",
    "    def reset_dic(self):\n",
    "        dic = {}\n",
    "        for key in self.keys:\n",
    "            dic[f\"{key}_{self.mode}_mse\"] = 0\n",
    "        self.dic = dic\n",
    "\n",
    "    def aggregate(self, u_pred, u_true):\n",
    "        n_samples = u_pred.shape[0]\n",
    "        for key in self.keys:\n",
    "            idx = KEY_TO_INDEX[self.dataset_name][key]\n",
    "            self.dic[f\"{key}_{self.mode}_mse\"] += (\n",
    "                (u_pred[..., idx, :] - u_true[..., idx, :])**2).mean()*n_samples\n",
    "\n",
    "    def get_dic(self):\n",
    "        dic = self.dic\n",
    "        for key in self.keys:\n",
    "            dic[f\"{key}_{self.mode}_mse\"] /= self.n_trajectories\n",
    "        return self.dic \n",
    "    \n",
    "if multichannel:\n",
    "    detailed_train_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                        dataset_name,\n",
    "                                        mode=\"train\",\n",
    "                                        n_trajectories=ntrain)\n",
    "    detailed_train_eval_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                        dataset_name,\n",
    "                                        mode=\"train_extra\",\n",
    "                                        n_trajectories=ntrain)\n",
    "    detailed_test_mse = DetailedMSE(list(KEY_TO_INDEX[dataset_name].keys()),\n",
    "                                    dataset_name,\n",
    "                                    mode=\"test\",\n",
    "                                    n_trajectories=ntest)\n",
    "else:\n",
    "    detailed_train_mse = None\n",
    "    detailed_train_eval_mse = None\n",
    "    detailed_test_mse = None\n",
    "    \n",
    "# Eval Coral on train and test set\n",
    "\n",
    "pred_train_inter_mse, code_train_inter_mse, pred_train_extra_mse, code_train_extra_mse, pred_train_mse, detailed_train_eval_mse = batch_eval_loop(\n",
    "    model, inr, train_extra_loader,\n",
    "    timestamps_test, detailed_train_eval_mse,\n",
    "    ntrain, multichannel, z_mean, z_std,\n",
    "    dataset_name, T_train\n",
    ")\n",
    "if T_train != T_test:\n",
    "    pred_test_inter_mse, code_test_inter_mse, pred_test_extra_mse, code_test_extra_mse, pred_test_mse, detailed_test_mse = batch_eval_loop(\n",
    "        model, inr, test_loader,\n",
    "        timestamps_test, detailed_test_mse,\n",
    "        ntest, multichannel, z_mean, z_std,\n",
    "        dataset_name, T_train\n",
    "    )\n",
    "elif T_train == T_test:\n",
    "    pred_test_mse, code_test_mse, detailed_test_mse = batch_eval_loop(\n",
    "        model, inr, test_loader,\n",
    "        timestamps_test, detailed_test_mse,\n",
    "        ntest, multichannel, z_mean, z_std,\n",
    "        dataset_name, None\n",
    "    )\n",
    "\n",
    "print(\"pred_train_inter_mse : \", pred_train_inter_mse.item())\n",
    "print('pred_train_extra_mse :' , pred_train_extra_mse.item())\n",
    "\n",
    "print(\"pred_test_inter_mse : \", pred_test_inter_mse.item())\n",
    "print('pred_test_extra_mse :' , pred_test_extra_mse.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
