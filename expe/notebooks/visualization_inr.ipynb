{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coral Experiments : up-sampling task\n",
    "\n",
    "This notebook presents the up-sampling capabilities of the CORAL framework. **This notebook requires that models have already been trained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 10 15:46:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp     On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   33C    P8     8W / 250W |      1MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/lise.leboudec/conda/envs/coral/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import omegaconf\n",
    "\n",
    "from coral.utils.data.load_data import get_dynamics_data, set_seed\n",
    "from expe.load_models.load_models_inr import load_coral, load_dino\n",
    "from expe.forwards.forwards_inr import forward_coral, forward_dino\n",
    "from expe.config.run_names import RUN_NAMES\n",
    "from coral.utils.data.dynamics_dataset import TemporalDatasetWithCode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    gpu_id = torch.cuda.current_device()\n",
    "    device = torch.device(f\"cuda:{gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"device : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inr_run_name :  legendary-sky-4204\n",
      "dyn_run_name :  jedi-parsec-4274\n",
      "dino_run_name :  carbonite-droid-4311\n",
      "running on 2 baselines\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/data/serrano/\"\n",
    "dataset_name = 'navier-stokes-dino'\n",
    "root_dir = Path(os.getenv(\"WANDB_DIR\")) / dataset_name\n",
    "sub_from = 4\n",
    "sub_tr = 0.2\n",
    "sub_te = 0.2\n",
    "inr_run_name =  RUN_NAMES[sub_from][sub_tr][\"coral\"][\"inr\"]\n",
    "dyn_run_name =  RUN_NAMES[sub_from][sub_tr][\"coral\"][\"dyn\"]\n",
    "dino_run_name =  RUN_NAMES[sub_from][sub_tr][\"dino\"]\n",
    "n_baselines = (inr_run_name != None) + \\\n",
    "                 (dino_run_name != None)\n",
    "\n",
    "print(\"inr_run_name : \", inr_run_name)\n",
    "print(\"dyn_run_name : \", dyn_run_name)\n",
    "print(\"dino_run_name : \", dino_run_name)\n",
    "print(f\"running on {n_baselines} baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dyn_run_name is not None: \n",
    "    cfg_coral_dyn = torch.load(root_dir / \"model\" / f\"{dyn_run_name}.pt\")['cfg']\n",
    "if inr_run_name is not None: \n",
    "    cfg_coral_inr = torch.load(root_dir / \"inr\" / f\"{inr_run_name}.pt\")['cfg']\n",
    "\n",
    "upsamplings = ['0', '1', '2', '4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in setting extrapolation with sampling 4 / 0.2 - 0.2\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "ntrain = cfg_coral_dyn.data.ntrain\n",
    "ntest = cfg_coral_dyn.data.ntest\n",
    "data_to_encode = cfg_coral_dyn.data.data_to_encode\n",
    "try:\n",
    "    sub_from = cfg_coral_dyn.data.sub_from\n",
    "except omegaconf.errors.ConfigAttributeError:\n",
    "    sub_from = sub_tr # firsts runs don't have a sub_from attribute ie run 4 / 1-1\n",
    "    sub_tr = 1\n",
    "    sub_te = 1\n",
    "seed = cfg_coral_dyn.data.seed\n",
    "same_grid = cfg_coral_dyn.data.same_grid\n",
    "setting = cfg_coral_dyn.data.setting\n",
    "sequence_length_optim = None\n",
    "sequence_length_in = cfg_coral_dyn.data.sequence_length_in\n",
    "sequence_length_out = cfg_coral_dyn.data.sequence_length_out\n",
    "\n",
    "print(f\"running in setting {setting} with sampling {sub_from} / {sub_tr} - {sub_te}\")\n",
    "\n",
    "# dino\n",
    "n_steps = 300\n",
    "lr_adapt = 0.005\n",
    "\n",
    "# coral\n",
    "code_dim_coral = cfg_coral_inr.inr.latent_dim\n",
    "width_dyn_coral = cfg_coral_dyn.dynamics.width\n",
    "depth_dyn_coral = cfg_coral_dyn.dynamics.depth\n",
    "inner_steps = cfg_coral_inr.optim.inner_steps\n",
    "\n",
    "# optim\n",
    "batch_size = 1\n",
    "batch_size_val = 1\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if dataset_name == 'shallow-water-dino':\n",
    "    multichannel = True\n",
    "else:\n",
    "    multichannel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments\n",
    "sub_from1 = 4\n",
    "sub_from2 = 2\n",
    "sub_from3 = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "(u_train, u_test, grid_tr, grid_te, _, _, _, _, u_train_ext, u_test_ext, grid_tr_ext, grid_te_ext) = get_dynamics_data(\n",
    "    data_dir,\n",
    "    dataset_name,\n",
    "    ntrain,\n",
    "    ntest,\n",
    "    sequence_length=sequence_length_optim,\n",
    "    sub_from=sub_from,\n",
    "    sub_tr=sub_tr,\n",
    "    sub_te=sub_te,\n",
    "    same_grid=same_grid,\n",
    "    setting=setting,\n",
    "    sequence_length_in=sequence_length_in,\n",
    "    sequence_length_out=sequence_length_out\n",
    ")\n",
    "\n",
    "(_, _, _, _, _, _, _, _, u_train_up1, u_test_up1, grid_tr_up1, grid_te_up1) = get_dynamics_data(\n",
    "    data_dir,\n",
    "    dataset_name,\n",
    "    ntrain,\n",
    "    ntest,\n",
    "    sequence_length=sequence_length_optim,\n",
    "    sub_from=sub_from1,\n",
    "    sub_tr=1,\n",
    "    sub_te=1,\n",
    "    same_grid=same_grid,\n",
    "    setting=setting,\n",
    "    sequence_length_in=sequence_length_in,\n",
    "    sequence_length_out=sequence_length_out\n",
    ")\n",
    "\n",
    "(_, _, _, _, _, _, _, _, u_train_up4, u_test_up4, grid_tr_up4, grid_te_up4) = get_dynamics_data(\n",
    "    data_dir,\n",
    "    dataset_name,\n",
    "    ntrain,\n",
    "    ntest,\n",
    "    sequence_length=sequence_length_optim,\n",
    "    sub_from=sub_from2,\n",
    "    sub_tr=1,\n",
    "    sub_te=1,\n",
    "    same_grid=same_grid,\n",
    "    setting=setting,\n",
    "    sequence_length_in=sequence_length_in,\n",
    "    sequence_length_out=sequence_length_out\n",
    ")\n",
    "\n",
    "(_, _, _, _, _, _, _, _, u_train_up16, u_test_up16, grid_tr_up16, grid_te_up16) = get_dynamics_data(\n",
    "    data_dir,\n",
    "    dataset_name,\n",
    "    ntrain,\n",
    "    ntest,\n",
    "    sequence_length=sequence_length_optim,\n",
    "    sub_from=sub_from3,\n",
    "    sub_tr=1,\n",
    "    sub_te=1,\n",
    "    same_grid=same_grid,\n",
    "    setting=setting,\n",
    "    sequence_length_in=sequence_length_in,\n",
    "    sequence_length_out=sequence_length_out\n",
    ")\n",
    "\n",
    "# flatten spatial dims\n",
    "u_train = einops.rearrange(u_train, 'B ... C T -> B (...) C T')\n",
    "grid_tr = einops.rearrange(grid_tr, 'B ... C T -> B (...) C T')  \n",
    "u_test = einops.rearrange(u_test, 'B ... C T -> B (...) C T')\n",
    "grid_te = einops.rearrange(grid_te, 'B ... C T -> B (...) C T')  \n",
    "if u_train_ext is not None:\n",
    "    u_train_ext = einops.rearrange(u_train_ext, 'B ... C T -> B (...) C T')\n",
    "    grid_tr_ext = einops.rearrange(\n",
    "        grid_tr_ext, 'B ... C T -> B (...) C T')  \n",
    "    u_test_ext = einops.rearrange(u_test_ext, 'B ... C T -> B (...) C T')\n",
    "    grid_te_ext = einops.rearrange(\n",
    "        grid_te_ext, 'B ... C T -> B (...) C T')  \n",
    "if u_train_up1 is not None:\n",
    "    u_train_up1 = einops.rearrange(u_train_up1, 'B ... C T -> B (...) C T')\n",
    "    grid_tr_up1 = einops.rearrange(\n",
    "        grid_tr_up1, 'B ... C T -> B (...) C T')  \n",
    "    u_test_up1 = einops.rearrange(u_test_up1, 'B ... C T -> B (...) C T')\n",
    "    grid_te_up1 = einops.rearrange(\n",
    "        grid_te_up1, 'B ... C T -> B (...) C T') \n",
    "if u_train_up4 is not None:\n",
    "    u_train_up4 = einops.rearrange(u_train_up4, 'B ... C T -> B (...) C T')\n",
    "    grid_tr_up4 = einops.rearrange(\n",
    "        grid_tr_up4, 'B ... C T -> B (...) C T')  \n",
    "    u_test_up4 = einops.rearrange(u_test_up4, 'B ... C T -> B (...) C T')\n",
    "    grid_te_up4 = einops.rearrange(\n",
    "        grid_te_up4, 'B ... C T -> B (...) C T') \n",
    "if u_train_up16 is not None:\n",
    "    u_train_up16 = einops.rearrange(u_train_up16, 'B ... C T -> B (...) C T')\n",
    "    grid_tr_up16 = einops.rearrange(\n",
    "        grid_tr_up16, 'B ... C T -> B (...) C T')  \n",
    "    u_test_up16 = einops.rearrange(u_test_up16, 'B ... C T -> B (...) C T')\n",
    "    grid_te_up16 = einops.rearrange(\n",
    "        grid_te_up16, 'B ... C T -> B (...) C T') \n",
    "\n",
    "print(\n",
    "    f\"data: {dataset_name}, u_train: {u_train.shape}, u_test: {u_test.shape}\")\n",
    "print(f\"grid: grid_tr: {grid_tr.shape}, grid_te: {grid_te.shape}\")\n",
    "if u_train_ext is not None:\n",
    "    print(\n",
    "        f\"data: {dataset_name}, u_train_ext: {u_train_ext.shape}, u_test_ext: {u_test_ext.shape}\")\n",
    "    print(\n",
    "        f\"grid: grid_tr_ext: {grid_tr_ext.shape}, grid_te_ext: {grid_te_ext.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq_train = u_train.shape[0]  # 512 en dur\n",
    "n_seq_test = u_test.shape[0]  # 512 en dur\n",
    "spatial_size = u_train.shape[1]  # 64 en dur\n",
    "state_dim = u_train.shape[2]  # N, XY, C, T\n",
    "coord_dim = grid_tr.shape[2]  # N, XY, C, T\n",
    "T = u_train.shape[-1]\n",
    "\n",
    "ntrain = u_train.shape[0]  # int(u_train.shape[0]*T)\n",
    "ntest = u_test.shape[0]  # int(u_test.shape[0]*T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TemporalDatasetWithCode(\n",
    "    u_train, grid_tr, code_dim_coral, dataset_name, data_to_encode\n",
    ")\n",
    "testset = TemporalDatasetWithCode(\n",
    "    u_test, grid_te, code_dim_coral, dataset_name, data_to_encode\n",
    ")\n",
    "if u_train_ext is not None:\n",
    "    trainset_ext = TemporalDatasetWithCode(\n",
    "        u_train_ext, grid_tr_ext, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_test_ext is not None:\n",
    "    testset_ext = TemporalDatasetWithCode(\n",
    "        u_test_ext, grid_te_ext, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_train_up1 is not None:\n",
    "    trainset_up1 = TemporalDatasetWithCode(\n",
    "        u_train_up1, grid_tr_up1, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_test_up1 is not None:\n",
    "    testset_up1 = TemporalDatasetWithCode(\n",
    "        u_test_up1, grid_te_up1, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_train_up4 is not None:\n",
    "    trainset_up4 = TemporalDatasetWithCode(\n",
    "        u_train_up4, grid_tr_up4, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_test_up4 is not None:\n",
    "    testset_up4 = TemporalDatasetWithCode(\n",
    "        u_test_up4, grid_te_up4, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_train_up16 is not None:\n",
    "    trainset_up16 = TemporalDatasetWithCode(\n",
    "        u_train_up16, grid_tr_up16, code_dim_coral, dataset_name, data_to_encode)\n",
    "if u_test_up16 is not None:\n",
    "    testset_up16 = TemporalDatasetWithCode(\n",
    "        u_test_up16, grid_te_up16, code_dim_coral, dataset_name, data_to_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size_val,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    drop_last=True,\n",
    ")\n",
    "if u_train_ext is not None:\n",
    "    train_loader_ext = torch.utils.data.DataLoader(\n",
    "        trainset_ext,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_test_ext is not None:\n",
    "    test_loader_ext = torch.utils.data.DataLoader(\n",
    "        testset_ext,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_train_up1 is not None:\n",
    "    train_loader_up1 = torch.utils.data.DataLoader(\n",
    "        trainset_up1,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_test_up1 is not None:\n",
    "    test_loader_up1 = torch.utils.data.DataLoader(\n",
    "        testset_up1,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_train_up4 is not None:\n",
    "    train_loader_up4 = torch.utils.data.DataLoader(\n",
    "        trainset_up4,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_test_up4 is not None:\n",
    "    test_loader_up4 = torch.utils.data.DataLoader(\n",
    "        testset_up4,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_train_up16 is not None:\n",
    "    train_loader_up16 = torch.utils.data.DataLoader(\n",
    "        trainset_up16,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )\n",
    "if u_test_up16 is not None:\n",
    "    test_loader_up16 = torch.utils.data.DataLoader(\n",
    "        testset_up16,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = u_train.shape[-1]\n",
    "if u_test_ext is not None:\n",
    "    T_EXT = u_test_ext.shape[-1]\n",
    "\n",
    "# trainset coords of shape (N, Dx, Dy, input_dim, T)\n",
    "input_dim = grid_tr.shape[-2]\n",
    "# trainset images of shape (N, Dx, Dy, output_dim, T)\n",
    "output_dim = u_train.shape[-2]\n",
    "\n",
    "dt = 1\n",
    "timestamps_train = torch.arange(0, T, dt).float().cuda()\n",
    "timestamps_ext = torch.arange(0, T_EXT, dt).float().cuda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, average loss: 7.169906737658494e-05\n",
      "Test, average loss: 0.027545505203306675\n",
      "dict_keys(['net.bilinear.0.A', 'net.bilinear.0.B', 'net.bilinear.0.bias', 'net.bilinear.1.A', 'net.bilinear.1.B', 'net.bilinear.1.bias', 'net.bilinear.2.A', 'net.bilinear.2.B', 'net.bilinear.2.bias', 'net.bilinear.3.A', 'net.bilinear.3.B', 'net.bilinear.3.bias', 'net.output_bilinear.weight', 'net.output_bilinear.bias', 'net.filters.0.weight', 'net.filters.1.weight', 'net.filters.2.weight', 'net.filters.3.weight'])\n",
      "dict_keys(['net.net.0.weight', 'net.net.0.bias', 'net.net.1.beta', 'net.net.2.weight', 'net.net.2.bias', 'net.net.3.beta', 'net.net.4.weight', 'net.net.4.bias', 'net.net.5.beta', 'net.net.6.weight', 'net.net.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "inr, alpha, dyn, z_mean, z_std = load_coral(root_dir, inr_run_name, dyn_run_name, data_to_encode, input_dim, output_dim, trainset, testset, multichannel, code_dim_coral, width_dyn_coral, depth_dyn_coral, inner_steps)\n",
    "net_dec, net_dyn, states_params, code_dim_dino = load_dino(root_dir, dino_run_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader_ext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_loader_ext))\n\u001b[1;32m      4\u001b[0m pred_coral0 \u001b[39m=\u001b[39m forward_coral(inr, dyn, batch, inner_steps, alpha, \u001b[39mTrue\u001b[39;00m, timestamps_ext, z_mean, z_std, dataset_name)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m pred_dino0 \u001b[39m=\u001b[39m forward_dino(net_dec, net_dyn, batch, n_seq_train, states_params, code_dim_dino, n_steps, lr_adapt, device, criterion, timestamps_ext, save_best\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrk4\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader_ext' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "batch = next(iter(test_loader_ext))\n",
    "pred_coral0 = forward_coral(inr, dyn, batch, inner_steps, alpha, True, timestamps_ext, z_mean, z_std, dataset_name).cpu().detach().numpy()\n",
    "pred_dino0 = forward_dino(net_dec, net_dyn, batch, n_seq_train, states_params, code_dim_dino, n_steps, lr_adapt, device, criterion, timestamps_ext, save_best=True, method=\"rk4\").cpu().detach().numpy()\n",
    "batch = next(iter(test_loader_up1))\n",
    "pred_coral1 = forward_coral(inr, dyn, batch, inner_steps, alpha, True, timestamps_ext, z_mean, z_std, dataset_name).cpu().detach().numpy()\n",
    "pred_dino1 = forward_dino(net_dec, net_dyn, batch, n_seq_train, states_params, code_dim_dino, n_steps, lr_adapt, device, criterion, timestamps_ext, save_best=True, method=\"rk4\").cpu().detach().numpy()\n",
    "batch = next(iter(test_loader_up4))\n",
    "pred_coral4 = forward_coral(inr, dyn, batch, inner_steps, alpha, True, timestamps_ext, z_mean, z_std, dataset_name).cpu().detach().numpy()\n",
    "pred_dino4 = forward_dino(net_dec, net_dyn, batch, n_seq_train, states_params, code_dim_dino, n_steps, lr_adapt, device, criterion, timestamps_ext, save_best=True, method=\"rk4\").cpu().detach().numpy()\n",
    "# batch = next(iter(test_loader_up16))\n",
    "# pred_coral16 = forward_coral(inr, dyn, batch, inner_steps, alpha, True, timestamps_ext, z_mean, z_std, dataset_name).cpu().detach().numpy()\n",
    "# pred_dino16 = forward_dino(net_dec, net_dyn, batch, n_seq_train, states_params, code_dim_dino, n_steps, lr_adapt, device, criterion, timestamps_ext, save_best=True, method=\"rk4\").cpu().detach().numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_coral0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[39m=\u001b[39m b0[\u001b[39m2\u001b[39m][\u001b[39m0\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m, time2show]\n\u001b[1;32m     11\u001b[0m y \u001b[39m=\u001b[39m b0[\u001b[39m2\u001b[39m][\u001b[39m0\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m, time2show]\n\u001b[0;32m---> 13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpred_coral0.shape : \u001b[39m\u001b[39m\"\u001b[39m, pred_coral0\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpred_coral1.shape : \u001b[39m\u001b[39m\"\u001b[39m, pred_coral1\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpred_coral4.shape : \u001b[39m\u001b[39m\"\u001b[39m, pred_coral4\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_coral0' is not defined"
     ]
    }
   ],
   "source": [
    "idx = [0]\n",
    "time2show = 20\n",
    "path = '/home/lise.leboudec/project/coral/xp/vis/'\n",
    "\n",
    "b0 = trainset_ext[idx]\n",
    "b1 = trainset_up1[idx]\n",
    "b4 = trainset_up4[idx]\n",
    "b16 = trainset_up16[idx]\n",
    "\n",
    "x = b0[2][0, ..., 0, time2show]\n",
    "y = b0[2][0, ..., 1, time2show]\n",
    "\n",
    "print(\"pred_coral0.shape : \", pred_coral0.shape)\n",
    "print(\"pred_coral1.shape : \", pred_coral1.shape)\n",
    "print(\"pred_coral4.shape : \", pred_coral4.shape)\n",
    "# print(\"pred_coral16.shape : \", pred_coral16.shape)\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 4))\n",
    "axs[0, 0].scatter(y, -x, 50, b0[0][0, ..., time2show], edgecolor=\"w\",\n",
    "    lw=0.2,)\n",
    "axs[0, 1].imshow(b1[0][0, ..., time2show].reshape(64, 64))\n",
    "# axs[0, 0].set_title(f\"Prediction, rel mse = {100*pred_test_mse:.2f}%\", fontsize=8)\n",
    "axs[0, 2].imshow(b4[0][0, ..., time2show].reshape(128, 128))\n",
    "# axs[0, 1].set_title(f\"Ground truth\", fontsize=8)\n",
    "axs[0, 3].imshow(b16[0][0, ..., time2show].reshape(256, 256))\n",
    "\n",
    "axs[1, 0].scatter(x, -y, 50, pred_coral0[0][0, ..., time2show], edgecolor=\"w\",\n",
    "    lw=0.2,)\n",
    "axs[1, 1].imshow(pred_coral1[0][0, ..., time2show])\n",
    "# axs[1, 0].set_title(f\"Prediction, rel mse = {100*pred_test_mse:.2f}%\", fontsize=8)\n",
    "axs[1, 2].imshow(pred_coral4[0][0, ..., time2show])\n",
    "# axs[1, 1].set_title(f\"Ground truth\", fontsize=8)\n",
    "# axs[1, 3].imshow(pred_coral16[0][0, ..., time2show])\n",
    "\n",
    "axs[1, 0].scatter(x, -y, 50, pred_dino0[0][0, ..., time2show], edgecolor=\"w\",\n",
    "    lw=0.2,)\n",
    "axs[1, 1].imshow(pred_dino1[0][0, ..., time2show])\n",
    "# axs[1, 0].set_title(f\"Prediction, rel mse = {100*pred_test_mse:.2f}%\", fontsize=8)\n",
    "axs[1, 2].imshow(pred_dino4[0][0, ..., time2show])\n",
    "# axs[1, 1].set_title(f\"Ground truth\", fontsize=8)\n",
    "# axs[1, 3].imshow(pred_dino16[0][0, ..., time2show])\n",
    "\n",
    "# plt.savefig(os.path.join(plot_dir, 'ns-upsampling64to256.png'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "def animate(i):\n",
    "    ax[0].imshow(b_te[0][0, ..., i])\n",
    "    ax[1].imshow(pred_te_coral[0][0, ..., i])\n",
    "    return ax\n",
    "\n",
    "ani = FuncAnimation(fig, animate, interval=40, repeat=True, frames=len(T_EXT))\n",
    "ani.save(path + \"vis_test_exp.gif\", dpi=300, writer=PillowWriter(fps=25))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "127dbb6062049e591e9816994f354e04a157b5303cc155de4e160edac2339a2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
